# План разработки плагина AutoCAD с чат-ассистентом

## 1. Цели и сценарии использования
- **Базовый сценарий**: пользователь вводит запрос вида «нарисуй круг радиусом 10, с центром в 0,0», ассистент выполняет команду в AutoCAD через tool-calls и/или AutoCAD API.
- **Расширенные сценарии**: пояснение чертежа, автодополнение команд, извлечение свойств объектов, подготовка макросов.
- **Ограничения**: AutoCAD 2019 (минимум), отсутствие интернет-доступа у пользователя ― предусмотреть оффлайн-режим с подсказкой, что LLM недоступен.

## 2. Высокоуровневая архитектура
- **AutoCAD .NET плагин** (`.dll`, .NET Framework 4.8) с точкой входа через `IExtensionApplication`.
- **UI-модуль**: палитра (PaletteSet) на WPF с полем ввода/чтения истории чата, кнопками управления и индикаторами статуса LLM.
- **Сервис команд**: слой выполнения запросов AutoCAD (через LLM или прямые .NET API), поддержка очереди действий, управление транзакциями, откат.
- **LLM-коннектор**: HTTP-клиент к OpenAI API (ChatGPT) с поддержкой стриминга, логирования, ретраев.
- **LLM-адаптер**: реализация клиента LLM Autocad для вызова предоставляемых сервером инструментов и публикации собственных команд.
- **Общие сервисы**: конфигурация (API-ключ, эндпоинты), кэш/память диалога, логирование (NLog/Serilog), телеметрия (по желанию).

## 3. Модули и их обязанности
- `PluginEntry`  
  - Регистрация команд и палитры, инициализация DI-контейнера, чтение конфигурации.
- `ChatPalette` (WPF)  
  - UI чата, отображение истории, состояние подключения, настройки.  
  - Интеграция с Markdown-рендером (дополнительно).
- `ConversationCoordinator`  
  - Управление очередностью запросов, маршрутизация для LLM, хранение контекста.
- `LlmClient`  
  - Работа с OpenAI API: формирование запросов, парсинг ответов, обработка ошибок/лимитов.  
  - Поддержка нескольких моделей (gpt-4o, gpt-4o-mini и т.п.).
- `ToolResolver`  
  - Каталог доступных LLM-инструментов и AutoCAD-команд, семантика безопасности (подтверждение опасных операций).
- `AutocadCommandExecutor`  
  - Выполнение действий на чертеже: построение примитивов, модификация, запрос геометрии.
- `Persistence` (опционально)  
  - Сохранение истории чатов и настроек в `%AppData%`/`LocalAppData`.
- `Configuration`  
  - Файлы настроек (`json`), шифрование API-ключа, UI для ввода ключа.
- `Logging`  
  - Единый интерфейс логирования, уровни (Debug/Info/Warn/Error), вывод в файл и окно событий.

## 4. Потоки данных
1. Пользователь вводит запрос в палитре.
2. `ConversationCoordinator` формирует сообщение контекста (описание рабочего чертежа, список доступных инструментов).
3. Сообщение уходит в `LlmClient`; при необходимости LLM запрашивает действия (через tool-calls).
4. `ToolResolver` проверяет и исполняет действия в AutoCAD (`AutocadCommandExecutor`), формирует результат.
5. Результат возвращается в LLM (если используется loop) либо сразу отображается пользователю.
6. История диалога и журнал действий сохраняются.

## 5. Интеграция с ChatGPT
- **Необходимое**: подписка с доступом к OpenAI API (ключ), модель `gpt-4o`/`gpt-4o-mini`.  
- **Подключение**: REST-запросы к `https://api.openai.com/v1/chat/completions`, заголовок `Authorization: Bearer <API_KEY>`, `Content-Type: application/json`.  
- **Архитектурные решения**:
  - Создать обертку для потокового чтения (`HttpClient` + `ReadAsStreamAsync`).
  - Настроить ретраи (например, Polly) и экспоненциальную задержку.
  - Возможность подменить провайдера (Azure OpenAI) через интерфейс `ILlmProvider`.
  - Ограничение количества токенов, настройка системных сообщений с описанием интерфейсов.
- **Безопасность**: хранить ключ в зашифрованном виде (DPAPI), не логировать ключ, при отсутствии ключа отображать UI-подсказку.

## 6. LLM интеграция
- Подключить официальный LLM-клиент или реализовать специфический транспорт (WebSocket / HTTP).  
- Определить контракт: список `tools` (команды AutoCAD), формат `messages`, обработка `call`.  
- Настроить двустороннюю связь:  
  1. LLM → tool-calls → плагин → AutoCAD.  
  2. Плагин → LLM (публикует контекст: активное пространство, доступные слои, выбранные объекты).  
- Обработать ошибки LLM (повторные вызовы, таймауты) и синхронизацию состояния.

## 7. План по этапам
1. **Подготовка инфраструктуры**: настроить проект (.NET Framework 4.8 class library), подключить AutoCAD .NET SDK, настроить подпись.  
2. **Базовая палитра**: создать WPF UI, подключить MVVM, обеспечить ввод/вывод сообщений.  
3. **LLM-коннектор**: реализовать клиент OpenAI, протестировать локально (без AutoCAD).  
4. **Командный исполнитель**: реализовать примитивы (круг, линия, полилиния), добавить защиту транзакций.  
5. **LLM-адаптер**: подключить к LLM Autocad, протестировать базовые tool-calls.  
6. **Интеграция**: связать чат, LLM, реализовать обработку ответов и визуальную обратную связь.  
7. **UX-доработки**: история диалогов, настройки модели, обработка ошибок в UI.  
8. **Тестирование**: сценарные тесты внутри AutoCAD, нагрузочные тесты LLM, журналы.  
9. **Документация и упаковка**: Readme, инструкции по установке (`Autodesk AppData/Roaming/Autodesk/ApplicationPlugins`), описание настроек.

## 8. Правила и договоренности
Смотри в файле rules.md.

## 9. Открытые вопросы и риски
- Наличие официального LLM-клиента для AutoCAD 2019: возможно потребуется обновление или кастомная интеграция.
- Ограничения лицензирования OpenAI API (стоимость, лимиты запросов).
- Потенциальные задержки сети — нужно продумать оффлайн-режим и отображение статуса.
- Безопасность: подтверждение опасных операций (удаление, массовые изменения).
- Совместимость с будущими версиями AutoCAD — стоит предусмотреть адаптационный слой.

## 10. Инструменты и практики
- IDE: Rider 2025 (с .NET Framework SDK).
- Логирование: NLog или Serilog + вывод в AutoCAD текстовый экран.
- Тестирование: интеграционные тесты через заглушки AutoCAD API (Moq), сценарии UI через запись макросов.
- CI (позже): GitHub Actions/DevOps для сборки DLL и публикации пакета.